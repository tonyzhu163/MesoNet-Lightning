{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "# import argparse\n",
    "from tqdm.notebook import tqdm\n",
    "from pathlib import Path\n",
    "import random\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "\n",
    "import torch.optim as optim\n",
    "\n",
    "from torchvision import transforms\n",
    "\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotted_dict import DottedDict\n",
    "\n",
    "args = DottedDict({\n",
    "    'base': 'C://Users//tonyz//PycharmProjects//DeepFake',\n",
    "    'batch_size': 32,\n",
    "    'pretrain': False,\n",
    "    'lr':1e-3,\n",
    "    'step_lr':True,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = Path(args.base)\n",
    "train_dir = base / 'data' / 'train'\n",
    "val_dir = base / 'data' / 'test'\n",
    "pretrain_dir = base /'data' / 'pretrained.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_val_mix(deepfake_method='Deepfakes'):\n",
    "    original = base / 'data' / 'original_sequences' / 'youtube' / 'c23' / 'images'\n",
    "    manipulated = base / 'data' / 'manipulated_sequences' / str(deepfake_method) / 'c23' / 'images'\n",
    "\n",
    "    if not os.path.exists(train_dir):\n",
    "        os.makedirs(train_dir)\n",
    "        os.makedirs(train_dir / '1')\n",
    "        os.makedirs(train_dir / '0')\n",
    "\n",
    "    if not os.path.exists(val_dir):\n",
    "        os.makedirs(val_dir)\n",
    "        os.makedirs(val_dir / '1')\n",
    "        os.makedirs(val_dir / '0')\n",
    "\n",
    "    # test_size = 0.33\n",
    "    test_size = 0.2\n",
    "\n",
    "    ori_sel = os.listdir(original)\n",
    "    man_sel = os.listdir(manipulated)\n",
    "\n",
    "    # random seed 42\n",
    "    random.seed(42)\n",
    "\n",
    "    for i, x in enumerate(ori_sel):\n",
    "        for file in (original / x).iterdir():\n",
    "            if random.uniform(0, 1) < test_size:\n",
    "                shutil.copy(file, val_dir / '0')\n",
    "            else:\n",
    "                shutil.copy(file, train_dir / '0')\n",
    "               \n",
    "    for i, x in enumerate(man_sel):\n",
    "       for file in (manipulated / x).iterdir():\n",
    "            if random.uniform(0, 1) < test_size:\n",
    "                shutil.copy(file, val_dir / '1')\n",
    "            else:\n",
    "                shutil.copy(file, train_dir / '1')\n",
    "\n",
    "if not os.path.exists(train_dir): \n",
    "    create_train_val_mix('Face2Face')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FaceForensics(pl.LightningDataModule):\n",
    "   def __init__(self):\n",
    "      super().__init__()\n",
    "      self.batch_size = args.batch_size\n",
    "\n",
    "      self.transform = transforms.Compose([\n",
    "      transforms.Resize((256, 256)),\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Normalize([0.5]*3, [0.5]*3)\n",
    "   ])\n",
    "\n",
    "   def train_dataloader(self):\n",
    "      train_dataset = torchvision.datasets.ImageFolder(train_dir, transform=self.transform)\n",
    "      train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=self.batch_size, shuffle=True, num_workers=4)\n",
    "      return train_loader\n",
    "   \n",
    "   def val_dataloader(self):\n",
    "      val_dataset = torchvision.datasets.ImageFolder(val_dir, transform=self.transform)\n",
    "      val_loader = torch.utils.data.DataLoader(val_dataset, batch_size=self.batch_size, shuffle=False, num_workers=4)\n",
    "      return val_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Meso4(pl.LightningModule):\n",
    "    def __init__(self, num_classes=2):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.conv1 = nn.Conv2d(3, 8, 3, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.leakyrelu = nn.LeakyReLU(0.1)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(8, 8, 5, padding=2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        self.conv3 = nn.Conv2d(8, 16, 5, padding=2, bias=False)\n",
    "        self.conv4 = nn.Conv2d(16, 16, 5, padding=2, bias=False)\n",
    "        self.maxpool1 = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.maxpool2 = nn.MaxPool2d(kernel_size=(4, 4))\n",
    "        self.dropout = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(16*8*8, 16)\n",
    "        self.fc2 = nn.Linear(16, num_classes)\n",
    "\n",
    "        self.loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "    # input is dim 256*256*3\n",
    "    # based on network architecture described in\n",
    "    # https://arxiv.org/pdf/1809.00888.pdf\n",
    "    def forward(self, input):\n",
    "        x = self.conv1(input)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn1(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        x = self.conv4(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.bn2(x)\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.leakyrelu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "\n",
    "        return x\n",
    "        \n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        # num_batches = len(self.train_dataloader()) / self.trainer.accumulate_grad_batches\n",
    "        # using hp from the original paper\n",
    "        optimizer = optim.Adam(self.parameters(), lr=args.lr)\n",
    "        lr_scheduler = {'scheduler': optim.lr_scheduler.StepLR(optimizer, step_size=1000, gamma=0.1),\n",
    "        }\n",
    "\n",
    "        return [optimizer], [lr_scheduler]\n",
    "    \n",
    "    def training_step(self, train_batch, batch_idx):\n",
    "        loss = 0\n",
    "        cnt = 0\n",
    "        acc = 0\n",
    "\n",
    "        img, lbl = train_batch\n",
    "        output = self.forward(img)\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "        \n",
    "        acc += torch.sum(preds == lbl.data).to(torch.float32)\n",
    "        loss += self.loss_fn(output, lbl)\n",
    "        cnt += len(lbl)\n",
    "\n",
    "        batch_dictionary={\n",
    "            \"loss\": loss,\n",
    "            \"correct\": acc,\n",
    "            \"total\": cnt\n",
    "        }\n",
    "\n",
    "        self.log(\"train_loss\", loss, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"train_acc\", acc/cnt, on_step=True, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return batch_dictionary\n",
    "    \n",
    "    def validation_step(self, val_batch, batch_idx):\n",
    "        loss = 0\n",
    "        cnt = 0\n",
    "        acc = 0\n",
    "\n",
    "        img, lbl = val_batch\n",
    "        output = self.forward(img)\n",
    "        _, preds = torch.max(output.data, 1)\n",
    "\n",
    "        acc += torch.sum(preds == lbl.data).to(torch.float32)\n",
    "        loss += self.loss_fn(output, lbl)\n",
    "        cnt += len(lbl)\n",
    "\n",
    "        batch_dictionary={\n",
    "            \"loss\": loss,\n",
    "            \"correct\": acc,\n",
    "            \"total\": cnt\n",
    "        }\n",
    "\n",
    "        self.log(\"val_loss\", loss, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "        self.log(\"val_acc\", acc/cnt, on_step=False, on_epoch=True, prog_bar=True, logger=True)\n",
    "\n",
    "        return batch_dictionary\n",
    "    \n",
    "    def on_train_epoch_end(self):\n",
    "        torch.cuda.empty_cache()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "   | Name      | Type             | Params\n",
      "------------------------------------------------\n",
      "0  | conv1     | Conv2d           | 216   \n",
      "1  | bn1       | BatchNorm2d      | 16    \n",
      "2  | relu      | ReLU             | 0     \n",
      "3  | leakyrelu | LeakyReLU        | 0     \n",
      "4  | conv2     | Conv2d           | 1.6 K \n",
      "5  | bn2       | BatchNorm2d      | 32    \n",
      "6  | conv3     | Conv2d           | 3.2 K \n",
      "7  | conv4     | Conv2d           | 6.4 K \n",
      "8  | maxpool1  | MaxPool2d        | 0     \n",
      "9  | maxpool2  | MaxPool2d        | 0     \n",
      "10 | dropout   | Dropout2d        | 0     \n",
      "11 | fc1       | Linear           | 16.4 K\n",
      "12 | fc2       | Linear           | 34    \n",
      "13 | loss_fn   | CrossEntropyLoss | 0     \n",
      "------------------------------------------------\n",
      "27.9 K    Trainable params\n",
      "0         Non-trainable params\n",
      "27.9 K    Total params\n",
      "0.112     Total estimated model params size (MB)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Sanity Checking: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "238f5b20b72a49ee9e84610904c8e9d2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tonyz\\miniconda3\\envs\\torch\\lib\\site-packages\\torch\\nn\\functional.py:1320: UserWarning: dropout2d: Received a 2-D input to dropout2d, which is deprecated and will result in an error in a future release. To retain the behavior and silence this warning, please use dropout instead. Note that dropout2d exists to provide channel-wise dropout on inputs with 2 spatial dimensions, a channel dimension, and an optional batch dimension (i.e. 3D or 4D inputs).\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/plain": "Training: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0bf637135742499c81dd43c7ed4a4c76"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "a5b84df562ef49a49fa0ab9982c90414"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "07a07272b25940c99fd851fbcf00da75"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f307d2dcc5174b2f9126052698708323"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c1ebdd10c750421eb99bcaab7245ed03"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "26b3a79f4e434edabb6a8f5651cd3159"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "7e45f17da4b548d39da87f1aa7a74837"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2b983f317a764282b998ea3680263bb9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "003b420a493446528378f45af309da16"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3c5f6173b5ee4df4916c9d0582ec7da7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "51fca4c07ab443f7983c576ce09c3ed1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "2bdbb9f5eb48410bb873d3c0a969f509"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "277c5d0d95014ec9920c5decdd6982bf"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d6ec147ecc7f4a11bb717b86c9ac6c5e"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c2cfaa1471964ce2abad31e75668e595"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "34bed7db86a54134911a20b0f7dc3fa9"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "39d31878a6ec437491adc52a39cf7f65"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "87649002166f46febd5c6cc07be521aa"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "c112200e32e3416f80935d2656f73cef"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "bb7f9e72467141fc99f4d699be1d9d44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "Validation: 0it [00:00, ?it/s]",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "25b1cdc394b14118b1a32b4dfa9b2493"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=20` reached.\n"
     ]
    }
   ],
   "source": [
    "FF = FaceForensics()\n",
    "model = Meso4()\n",
    "\n",
    "if args.pretrain:\n",
    "    model.load_state_dict(torch.load(pretrain_dir))\n",
    "\n",
    "logger = TensorBoardLogger('lightning_logs', name='logger')\n",
    "\n",
    "trainer = pl.Trainer(max_epochs=20, logger=logger, accelerator='gpu', max_time={'minutes':30}, limit_val_batches=0.5,\n",
    "                     default_root_dir = base / 'model' / 'checkpoints')\n",
    "\n",
    "trainer.fit(model,datamodule=FF)\n",
    "# trainer.validate(model, datamodule=FF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(\"20_epoch_other.ckpt\")"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": "Launching TensorBoard..."
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "\n      <iframe id=\"tensorboard-frame-b50b2226587a536e\" width=\"100%\" height=\"800\" frameborder=\"0\">\n      </iframe>\n      <script>\n        (function() {\n          const frame = document.getElementById(\"tensorboard-frame-b50b2226587a536e\");\n          const url = new URL(\"/\", window.location);\n          const port = 6006;\n          if (port) {\n            url.port = port;\n          }\n          frame.src = url;\n        })();\n      </script>\n    "
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%reload_ext tensorboard\n",
    "%tensorboard --logdir=lightning_logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
